<h2>
 Social Bias in Large Language Models For Bangla: An Empirical Study on Gender and Religious Bias
</h2>
<div>
 <b>
     Abstract
 <b>
 <p>
     They worked two types of social biases in LLM generated outputs for Bangla Language. All of the resources publically available 
 </p>
 <b>
     Main Contribution
 </b>
 <p>
  <ol>
   <li>  
     Bias studies on two different social biases for
     Bangla (Regious & Gender Bias)
   </li>
   <li>    
     A curated dataset for bias measurement benchmarking  
   </li>
   <li>    
     Testing two different probing techniques for bias detection in the
     context of Bangla.
   </li>
  </ol>
  
 </p>
 <p>
     <b>
     Introduction
     </b>
     <p>
          They used two strategies for LLM probing: Template Based and Naturally Sourced.
     </p>
     <b>
          Template Based
     </b>
     <p>
          They created template with placeholders for specific traits filled with adjective words from categories like Personality, Outlook, Communal, and Occupation. They got 2772 template sentences by combining both the
          categories
     </p>
     <b>
          Naturally Sourced
     </b>
     <p>
          They use the BIBED dataset (Das et al., 2023), specifically the Explicit Bias Evaluation (EBE) data for naturally occurring scenarios.After curation, 2416 pairs were retained for gender and 1535 for religion
     </p>

 <p>
 <p>
     <b>
          Experimental Setup
     </b>
     <p>
          For their experiment they provide results for four
          state-of-the-art LLMs: Llama3-8b (version: MetaLlama-3-8B-Instruct 3
          ) (AI@Meta, 2024), GPT3.5-Turbo 4
          , GPT-4o 5
          and Claude-3.5-Sonnet
     </p>
 </p>
</div>
