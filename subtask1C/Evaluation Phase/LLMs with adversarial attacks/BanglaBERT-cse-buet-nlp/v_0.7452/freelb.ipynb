{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138eefd1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-28T01:24:36.355666Z",
     "iopub.status.busy": "2025-08-28T01:24:36.355387Z",
     "iopub.status.idle": "2025-08-28T01:24:37.798887Z",
     "shell.execute_reply": "2025-08-28T01:24:37.798274Z"
    },
    "papermill": {
     "duration": 1.448681,
     "end_time": "2025-08-28T01:24:37.800488",
     "exception": false,
     "start_time": "2025-08-28T01:24:36.351807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cc3f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T01:24:37.806777Z",
     "iopub.status.busy": "2025-08-28T01:24:37.806421Z",
     "iopub.status.idle": "2025-08-28T07:29:49.293124Z",
     "shell.execute_reply": "2025-08-28T07:29:49.292187Z"
    },
    "papermill": {
     "duration": 21911.491587,
     "end_time": "2025-08-28T07:29:49.294502",
     "exception": false,
     "start_time": "2025-08-28T01:24:37.802915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-28 01:24:38--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_dev.tsv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 634005 (619K) [text/plain]\r\n",
      "Saving to: ‘blp25_hatespeech_subtask_1C_dev.tsv’\r\n",
      "\r\n",
      "blp25_hatespeech_su 100%[===================>] 619.15K  --.-KB/s    in 0.04s   \r\n",
      "\r\n",
      "2025-08-28 01:24:38 (14.3 MB/s) - ‘blp25_hatespeech_subtask_1C_dev.tsv’ saved [634005/634005]\r\n",
      "\r\n",
      "--2025-08-28 01:24:38--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_dev_test.tsv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 548258 (535K) [text/plain]\r\n",
      "Saving to: ‘blp25_hatespeech_subtask_1C_dev_test.tsv’\r\n",
      "\r\n",
      "blp25_hatespeech_su 100%[===================>] 535.41K  --.-KB/s    in 0.04s   \r\n",
      "\r\n",
      "2025-08-28 01:24:38 (14.9 MB/s) - ‘blp25_hatespeech_subtask_1C_dev_test.tsv’ saved [548258/548258]\r\n",
      "\r\n",
      "--2025-08-28 01:24:38--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_train.tsv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 8686966 (8.3M) [application/octet-stream]\r\n",
      "Saving to: ‘blp25_hatespeech_subtask_1C_train.tsv’\r\n",
      "\r\n",
      "blp25_hatespeech_su 100%[===================>]   8.28M  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2025-08-28 01:24:39 (83.5 MB/s) - ‘blp25_hatespeech_subtask_1C_train.tsv’ saved [8686966/8686966]\r\n",
      "\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\r\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\r\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fsspec\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.5.1\r\n",
      "    Uninstalling fsspec-2025.5.1:\r\n",
      "      Successfully uninstalled fsspec-2025.5.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed fsspec-2025.3.0\r\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.5\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 01:26:51.929377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756344412.122523      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756344412.181417      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset size: 38034\n",
      "Test dataset size: 2512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16204103c5242c5a05b7cb0ea5f37e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341b7c2c3e004ce58f85b425bc2e6576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 01:27:09,790 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 01:27:09,798 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b120d44bb44c50acbd8b936b855f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c950739aa18e45229d4bdb3ba91c7c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,545 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,546 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,547 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,547 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,548 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-08-28 01:27:10,549 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 01:27:10,551 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 01:27:10,552 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 01:27:10,602 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 01:27:10,604 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758705a73de64c039071bc7e0384debe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/38034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f254bc70923242168023cb63cd007d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples for cross-validation: 38034\n",
      "Label distribution: [21405   714   133  4518  2488  8776]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762d888443df4dbfa3dc7f667d181b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train size: 30427, Validation size: 7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 01:27:25,076 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 01:27:25,078 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67ac9527f1c4a6c9b0b8f08b8c348a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1151] 2025-08-28 01:27:32,631 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-28 01:27:32,748 >> Attempting to create safetensors variant\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-28 01:27:33,101 >> Safetensors PR exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbf9cec6a07475c9ce44867b8587672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:5121] 2025-08-28 01:27:33,466 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|modeling_utils.py:5139] 2025-08-28 01:27:33,467 >> All the weights of ElectraModel were initialized from the model checkpoint at csebuetnlp/banglabert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 01:27:33,561 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 01:27:33,563 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|training_args.py:2135] 2025-08-28 01:27:33,568 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-08-28 01:27:33,600 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|integration_utils.py:101] 2025-08-28 01:27:33,603 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_19/2845165665.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "[INFO|trainer.py:934] 2025-08-28 01:27:36,081 >> The following columns in the Training set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2409] 2025-08-28 01:27:36,117 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-08-28 01:27:36,118 >>   Num examples = 30,427\n",
      "[INFO|trainer.py:2411] 2025-08-28 01:27:36,119 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2412] 2025-08-28 01:27:36,119 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2414] 2025-08-28 01:27:36,120 >>   Training with DataParallel so batch size has been adjusted to: 8\n",
      "[INFO|trainer.py:2415] 2025-08-28 01:27:36,121 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-08-28 01:27:36,122 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2417] 2025-08-28 01:27:36,123 >>   Total optimization steps = 1,902\n",
      "[INFO|trainer.py:2418] 2025-08-28 01:27:36,125 >>   Number of trainable parameters = 110,037,518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 1:08:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hate Accuracy</th>\n",
       "      <th>Severity Accuracy</th>\n",
       "      <th>To Whom Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.604200</td>\n",
       "      <td>2.208773</td>\n",
       "      <td>0.702248</td>\n",
       "      <td>0.742211</td>\n",
       "      <td>0.701591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.007400</td>\n",
       "      <td>2.124928</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.740239</td>\n",
       "      <td>0.721178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 01:59:11,458 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 01:59:11,464 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 01:59:11,465 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 01:59:11,465 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 02:01:57,197 >> Saving model checkpoint to ./freelb_fold_1/checkpoint-951\n",
      "[INFO|trainer.py:4007] 2025-08-28 02:01:57,200 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 02:01:58,117 >> tokenizer config file saved in ./freelb_fold_1/checkpoint-951/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 02:01:58,119 >> Special tokens file saved in ./freelb_fold_1/checkpoint-951/special_tokens_map.json\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:934] 2025-08-28 02:33:40,194 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 02:33:40,199 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 02:33:40,200 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 02:33:40,200 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 02:36:25,455 >> Saving model checkpoint to ./freelb_fold_1/checkpoint-1902\n",
      "[INFO|trainer.py:4007] 2025-08-28 02:36:25,458 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 02:36:26,377 >> tokenizer config file saved in ./freelb_fold_1/checkpoint-1902/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 02:36:26,378 >> Special tokens file saved in ./freelb_fold_1/checkpoint-1902/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-08-28 02:36:27,785 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2907] 2025-08-28 02:36:27,786 >> Loading best model from ./freelb_fold_1/checkpoint-1902 (score: 2.1249284744262695).\n",
      "[INFO|trainer.py:2717] 2025-08-28 02:36:27,966 >> Deleting older checkpoint [freelb_fold_1/checkpoint-951] due to args.save_total_limit\n",
      "[INFO|trainer.py:934] 2025-08-28 02:36:28,237 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 02:36:28,242 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 02:36:28,242 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 02:36:28,243 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 02:39:13,851 >> The following columns in the test set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 02:39:13,856 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 02:39:13,857 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4332] 2025-08-28 02:39:13,858 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 1 model...\n",
      "Fold 1 - Hate Accuracy: 0.7109, Severity Accuracy: 0.7402, To Whom Accuracy: 0.7212\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train size: 30427, Validation size: 7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 02:40:08,465 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 02:40:08,466 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-08-28 02:40:08,620 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-28 02:40:08,727 >> Attempting to create safetensors variant\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-28 02:40:09,010 >> Safetensors PR exists\n",
      "[INFO|modeling_utils.py:5121] 2025-08-28 02:40:09,225 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|modeling_utils.py:5139] 2025-08-28 02:40:09,225 >> All the weights of ElectraModel were initialized from the model checkpoint at csebuetnlp/banglabert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 02:40:09,319 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 02:40:09,321 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|training_args.py:2135] 2025-08-28 02:40:09,323 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-08-28 02:40:09,353 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|integration_utils.py:101] 2025-08-28 02:40:09,355 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_19/2845165665.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 02:40:10,229 >> The following columns in the Training set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2409] 2025-08-28 02:40:10,237 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-08-28 02:40:10,238 >>   Num examples = 30,427\n",
      "[INFO|trainer.py:2411] 2025-08-28 02:40:10,238 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2412] 2025-08-28 02:40:10,239 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2414] 2025-08-28 02:40:10,239 >>   Training with DataParallel so batch size has been adjusted to: 8\n",
      "[INFO|trainer.py:2415] 2025-08-28 02:40:10,240 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-08-28 02:40:10,242 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2417] 2025-08-28 02:40:10,242 >>   Total optimization steps = 1,902\n",
      "[INFO|trainer.py:2418] 2025-08-28 02:40:10,243 >>   Number of trainable parameters = 110,037,518\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 1:08:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hate Accuracy</th>\n",
       "      <th>Severity Accuracy</th>\n",
       "      <th>To Whom Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.551000</td>\n",
       "      <td>2.126442</td>\n",
       "      <td>0.716971</td>\n",
       "      <td>0.743394</td>\n",
       "      <td>0.708952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.976300</td>\n",
       "      <td>2.106570</td>\n",
       "      <td>0.722230</td>\n",
       "      <td>0.738793</td>\n",
       "      <td>0.715525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 03:11:49,101 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 03:11:49,106 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 03:11:49,107 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 03:11:49,107 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 03:14:34,430 >> Saving model checkpoint to ./freelb_fold_2/checkpoint-951\n",
      "[INFO|trainer.py:4007] 2025-08-28 03:14:34,434 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 03:14:35,309 >> tokenizer config file saved in ./freelb_fold_2/checkpoint-951/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 03:14:35,310 >> Special tokens file saved in ./freelb_fold_2/checkpoint-951/special_tokens_map.json\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:934] 2025-08-28 03:46:16,628 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 03:46:16,633 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 03:46:16,634 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 03:46:16,635 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 03:49:01,588 >> Saving model checkpoint to ./freelb_fold_2/checkpoint-1902\n",
      "[INFO|trainer.py:4007] 2025-08-28 03:49:01,591 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 03:49:02,409 >> tokenizer config file saved in ./freelb_fold_2/checkpoint-1902/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 03:49:02,410 >> Special tokens file saved in ./freelb_fold_2/checkpoint-1902/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-08-28 03:49:03,735 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2907] 2025-08-28 03:49:03,735 >> Loading best model from ./freelb_fold_2/checkpoint-1902 (score: 2.106570243835449).\n",
      "[INFO|trainer.py:2717] 2025-08-28 03:49:03,899 >> Deleting older checkpoint [freelb_fold_2/checkpoint-951] due to args.save_total_limit\n",
      "[INFO|trainer.py:934] 2025-08-28 03:49:04,166 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 03:49:04,172 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 03:49:04,173 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 03:49:04,173 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 03:51:49,370 >> The following columns in the test set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 03:51:49,375 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 03:51:49,376 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4332] 2025-08-28 03:51:49,377 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 2 model...\n",
      "Fold 2 - Hate Accuracy: 0.7222, Severity Accuracy: 0.7388, To Whom Accuracy: 0.7155\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train size: 30427, Validation size: 7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 03:52:43,833 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 03:52:43,834 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-08-28 03:52:43,939 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-28 03:52:44,045 >> Attempting to create safetensors variant\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-28 03:52:44,450 >> Safetensors PR exists\n",
      "[INFO|modeling_utils.py:5121] 2025-08-28 03:52:44,513 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|modeling_utils.py:5139] 2025-08-28 03:52:44,514 >> All the weights of ElectraModel were initialized from the model checkpoint at csebuetnlp/banglabert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 03:52:44,606 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 03:52:44,607 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|training_args.py:2135] 2025-08-28 03:52:44,609 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-08-28 03:52:44,643 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|integration_utils.py:101] 2025-08-28 03:52:44,645 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_19/2845165665.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 03:52:45,471 >> The following columns in the Training set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2409] 2025-08-28 03:52:45,478 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-08-28 03:52:45,479 >>   Num examples = 30,427\n",
      "[INFO|trainer.py:2411] 2025-08-28 03:52:45,479 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2412] 2025-08-28 03:52:45,480 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2414] 2025-08-28 03:52:45,480 >>   Training with DataParallel so batch size has been adjusted to: 8\n",
      "[INFO|trainer.py:2415] 2025-08-28 03:52:45,481 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-08-28 03:52:45,482 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2417] 2025-08-28 03:52:45,483 >>   Total optimization steps = 1,902\n",
      "[INFO|trainer.py:2418] 2025-08-28 03:52:45,484 >>   Number of trainable parameters = 110,037,518\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 1:08:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hate Accuracy</th>\n",
       "      <th>Severity Accuracy</th>\n",
       "      <th>To Whom Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>2.252484</td>\n",
       "      <td>0.702511</td>\n",
       "      <td>0.732089</td>\n",
       "      <td>0.702248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.013400</td>\n",
       "      <td>2.182443</td>\n",
       "      <td>0.703694</td>\n",
       "      <td>0.738925</td>\n",
       "      <td>0.708295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 04:24:20,152 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 04:24:20,156 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 04:24:20,157 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 04:24:20,157 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 04:27:04,660 >> Saving model checkpoint to ./freelb_fold_3/checkpoint-951\n",
      "[INFO|trainer.py:4007] 2025-08-28 04:27:04,663 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 04:27:05,464 >> tokenizer config file saved in ./freelb_fold_3/checkpoint-951/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 04:27:05,466 >> Special tokens file saved in ./freelb_fold_3/checkpoint-951/special_tokens_map.json\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:934] 2025-08-28 04:58:40,972 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 04:58:40,977 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 04:58:40,978 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 04:58:40,978 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 05:01:25,369 >> Saving model checkpoint to ./freelb_fold_3/checkpoint-1902\n",
      "[INFO|trainer.py:4007] 2025-08-28 05:01:25,372 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 05:01:26,168 >> tokenizer config file saved in ./freelb_fold_3/checkpoint-1902/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 05:01:26,169 >> Special tokens file saved in ./freelb_fold_3/checkpoint-1902/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-08-28 05:01:27,475 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2907] 2025-08-28 05:01:27,475 >> Loading best model from ./freelb_fold_3/checkpoint-1902 (score: 2.1824429035186768).\n",
      "[INFO|trainer.py:2717] 2025-08-28 05:01:27,637 >> Deleting older checkpoint [freelb_fold_3/checkpoint-951] due to args.save_total_limit\n",
      "[INFO|trainer.py:934] 2025-08-28 05:01:27,894 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 05:01:27,898 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 05:01:27,899 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 05:01:27,899 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 05:04:12,638 >> The following columns in the test set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 05:04:12,642 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 05:04:12,643 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4332] 2025-08-28 05:04:12,643 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 3 model...\n",
      "Fold 3 - Hate Accuracy: 0.7037, Severity Accuracy: 0.7389, To Whom Accuracy: 0.7083\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train size: 30427, Validation size: 7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 05:05:06,993 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 05:05:06,995 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-08-28 05:05:07,083 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-28 05:05:07,211 >> Attempting to create safetensors variant\n",
      "[INFO|modeling_utils.py:5121] 2025-08-28 05:05:07,624 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|modeling_utils.py:5139] 2025-08-28 05:05:07,625 >> All the weights of ElectraModel were initialized from the model checkpoint at csebuetnlp/banglabert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 05:05:07,724 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 05:05:07,726 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|training_args.py:2135] 2025-08-28 05:05:07,728 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-08-28 05:05:07,756 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|integration_utils.py:101] 2025-08-28 05:05:07,758 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_19/2845165665.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-28 05:05:08,339 >> Safetensors PR exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 05:05:08,542 >> The following columns in the Training set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2409] 2025-08-28 05:05:08,549 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-08-28 05:05:08,550 >>   Num examples = 30,427\n",
      "[INFO|trainer.py:2411] 2025-08-28 05:05:08,551 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2412] 2025-08-28 05:05:08,551 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2414] 2025-08-28 05:05:08,552 >>   Training with DataParallel so batch size has been adjusted to: 8\n",
      "[INFO|trainer.py:2415] 2025-08-28 05:05:08,552 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-08-28 05:05:08,553 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2417] 2025-08-28 05:05:08,553 >>   Total optimization steps = 1,902\n",
      "[INFO|trainer.py:2418] 2025-08-28 05:05:08,555 >>   Number of trainable parameters = 110,037,518\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 1:08:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hate Accuracy</th>\n",
       "      <th>Severity Accuracy</th>\n",
       "      <th>To Whom Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.570200</td>\n",
       "      <td>2.174953</td>\n",
       "      <td>0.707375</td>\n",
       "      <td>0.744709</td>\n",
       "      <td>0.702774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.986100</td>\n",
       "      <td>2.130526</td>\n",
       "      <td>0.706060</td>\n",
       "      <td>0.744183</td>\n",
       "      <td>0.708689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 05:36:41,745 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 05:36:41,750 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 05:36:41,751 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 05:36:41,751 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 05:39:26,410 >> Saving model checkpoint to ./freelb_fold_4/checkpoint-951\n",
      "[INFO|trainer.py:4007] 2025-08-28 05:39:26,413 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 05:39:27,199 >> tokenizer config file saved in ./freelb_fold_4/checkpoint-951/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 05:39:27,200 >> Special tokens file saved in ./freelb_fold_4/checkpoint-951/special_tokens_map.json\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:934] 2025-08-28 06:11:01,019 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 06:11:01,023 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 06:11:01,024 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 06:11:01,024 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 06:13:45,168 >> Saving model checkpoint to ./freelb_fold_4/checkpoint-1902\n",
      "[INFO|trainer.py:4007] 2025-08-28 06:13:45,170 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 06:13:45,959 >> tokenizer config file saved in ./freelb_fold_4/checkpoint-1902/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 06:13:45,960 >> Special tokens file saved in ./freelb_fold_4/checkpoint-1902/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-08-28 06:13:47,258 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2907] 2025-08-28 06:13:47,259 >> Loading best model from ./freelb_fold_4/checkpoint-1902 (score: 2.130525827407837).\n",
      "[INFO|trainer.py:2717] 2025-08-28 06:13:47,424 >> Deleting older checkpoint [freelb_fold_4/checkpoint-951] due to args.save_total_limit\n",
      "[INFO|trainer.py:934] 2025-08-28 06:13:47,687 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 06:13:47,693 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 06:13:47,693 >>   Num examples = 7607\n",
      "[INFO|trainer.py:4332] 2025-08-28 06:13:47,694 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 06:16:32,559 >> The following columns in the test set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 06:16:32,564 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 06:16:32,564 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4332] 2025-08-28 06:16:32,565 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 4 model...\n",
      "Fold 4 - Hate Accuracy: 0.7061, Severity Accuracy: 0.7442, To Whom Accuracy: 0.7087\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train size: 30428, Validation size: 7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-08-28 06:17:26,819 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 06:17:26,821 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-08-28 06:17:26,928 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-28 06:17:27,036 >> Attempting to create safetensors variant\n",
      "[INFO|modeling_utils.py:5121] 2025-08-28 06:17:27,495 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|modeling_utils.py:5139] 2025-08-28 06:17:27,496 >> All the weights of ElectraModel were initialized from the model checkpoint at csebuetnlp/banglabert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:698] 2025-08-28 06:17:27,596 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-08-28 06:17:27,597 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|training_args.py:2135] 2025-08-28 06:17:27,599 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-08-28 06:17:27,628 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|integration_utils.py:101] 2025-08-28 06:17:27,629 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_19/2845165665.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-28 06:17:27,747 >> Safetensors PR exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 06:17:28,457 >> The following columns in the Training set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2409] 2025-08-28 06:17:28,464 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-08-28 06:17:28,464 >>   Num examples = 30,428\n",
      "[INFO|trainer.py:2411] 2025-08-28 06:17:28,465 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2412] 2025-08-28 06:17:28,466 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2414] 2025-08-28 06:17:28,467 >>   Training with DataParallel so batch size has been adjusted to: 8\n",
      "[INFO|trainer.py:2415] 2025-08-28 06:17:28,467 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-08-28 06:17:28,468 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2417] 2025-08-28 06:17:28,469 >>   Total optimization steps = 1,902\n",
      "[INFO|trainer.py:2418] 2025-08-28 06:17:28,470 >>   Number of trainable parameters = 110,037,518\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1902' max='1902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1902/1902 1:08:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hate Accuracy</th>\n",
       "      <th>Severity Accuracy</th>\n",
       "      <th>To Whom Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.569000</td>\n",
       "      <td>2.134129</td>\n",
       "      <td>0.713121</td>\n",
       "      <td>0.746647</td>\n",
       "      <td>0.712595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.991800</td>\n",
       "      <td>2.117434</td>\n",
       "      <td>0.711412</td>\n",
       "      <td>0.739022</td>\n",
       "      <td>0.717328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 06:49:02,970 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 06:49:02,975 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 06:49:02,976 >>   Num examples = 7606\n",
      "[INFO|trainer.py:4332] 2025-08-28 06:49:02,977 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 06:51:47,509 >> Saving model checkpoint to ./freelb_fold_5/checkpoint-951\n",
      "[INFO|trainer.py:4007] 2025-08-28 06:51:47,511 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 06:51:48,310 >> tokenizer config file saved in ./freelb_fold_5/checkpoint-951/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 06:51:48,311 >> Special tokens file saved in ./freelb_fold_5/checkpoint-951/special_tokens_map.json\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:934] 2025-08-28 07:23:23,768 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 07:23:23,773 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 07:23:23,773 >>   Num examples = 7606\n",
      "[INFO|trainer.py:4332] 2025-08-28 07:23:23,774 >>   Batch size = 16\n",
      "[INFO|trainer.py:3993] 2025-08-28 07:26:07,996 >> Saving model checkpoint to ./freelb_fold_5/checkpoint-1902\n",
      "[INFO|trainer.py:4007] 2025-08-28 07:26:07,999 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-08-28 07:26:08,808 >> tokenizer config file saved in ./freelb_fold_5/checkpoint-1902/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-08-28 07:26:08,809 >> Special tokens file saved in ./freelb_fold_5/checkpoint-1902/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-08-28 07:26:10,103 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2907] 2025-08-28 07:26:10,104 >> Loading best model from ./freelb_fold_5/checkpoint-1902 (score: 2.117433547973633).\n",
      "[INFO|trainer.py:2717] 2025-08-28 07:26:10,268 >> Deleting older checkpoint [freelb_fold_5/checkpoint-951] due to args.save_total_limit\n",
      "[INFO|trainer.py:934] 2025-08-28 07:26:10,523 >> The following columns in the Evaluation set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids, to_whom, hate_type, hate_severity. If text, token_type_ids, to_whom, hate_type, hate_severity are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 07:26:10,528 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 07:26:10,529 >>   Num examples = 7606\n",
      "[INFO|trainer.py:4332] 2025-08-28 07:26:10,529 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:934] 2025-08-28 07:28:55,286 >> The following columns in the test set don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: text, token_type_ids. If text, token_type_ids are not expected by `MultiTaskModel.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4327] 2025-08-28 07:28:55,290 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4329] 2025-08-28 07:28:55,291 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4332] 2025-08-28 07:28:55,291 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 5 model...\n",
      "Fold 5 - Hate Accuracy: 0.7114, Severity Accuracy: 0.7390, To Whom Accuracy: 0.7173\n",
      "\n",
      "==================================================\n",
      "CROSS-VALIDATION COMPLETED\n",
      "==================================================\n",
      "\n",
      "Cross-Validation Results:\n",
      "   fold  train_loss  eval_loss  eval_hate_accuracy  eval_severity_accuracy  \\\n",
      "0     1    2.305819   2.124928            0.710924                0.740239   \n",
      "1     2    2.263611   2.106570            0.722230                0.738793   \n",
      "2     3    2.311663   2.182443            0.703694                0.738925   \n",
      "3     4    2.278173   2.130526            0.706060                0.744183   \n",
      "4     5    2.280419   2.117434            0.711412                0.739022   \n",
      "\n",
      "   eval_to_whom_accuracy  \n",
      "0               0.721178  \n",
      "1               0.715525  \n",
      "2               0.708295  \n",
      "3               0.708689  \n",
      "4               0.717328  \n",
      "\n",
      "Average Results Across 5 Folds:\n",
      "Average Training Loss: 2.2879\n",
      "Average Validation Loss: 2.1324\n",
      "Average Hate Type Accuracy: 0.7109 ± 0.0071\n",
      "Average Severity Accuracy: 0.7402 ± 0.0023\n",
      "Average To Whom Accuracy: 0.7142 ± 0.0056\n",
      "\n",
      "Predictions saved to './freelb_banglabert/subtask_1C.tsv'\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_dev.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_dev_test.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1C/blp25_hatespeech_subtask_1C_train.tsv\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "# !pip install --upgrade accelerate\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "train_file = 'blp25_hatespeech_subtask_1C_train.tsv'\n",
    "validation_file = 'blp25_hatespeech_subtask_1C_dev.tsv'\n",
    "test_file = 'blp25_hatespeech_subtask_1C_dev_test.tsv'\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,  # Reduced to save memory\n",
    "    per_device_train_batch_size=4,  # Small batch size for FreeLB memory requirements\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,  # Use gradient accumulation to maintain effective batch size\n",
    "    output_dir=\"./freelb_banglabert/\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    local_rank= 1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=None,\n",
    "    warmup_ratio=0.1,  # Add warmup as recommended in FreeLB paper\n",
    "    weight_decay=0.01,  # Add weight decay for better regularization\n",
    "    fp16=False  # Disable FP16 for FreeLB compatibility\n",
    ")\n",
    "\n",
    "max_train_samples = None\n",
    "max_eval_samples=None\n",
    "max_predict_samples=None\n",
    "max_seq_length = 512\n",
    "batch_size = 16\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "model_name = 'csebuetnlp/banglabert'\n",
    "set_seed(training_args.seed)\n",
    "hate_type_map = {'None': 0, 'Religious Hate': 1, 'Sexism': 2, 'Political Hate': 3, 'Profane': 4, 'Abusive': 5}\n",
    "severity_map = {'Little to None': 0, 'Mild': 1, 'Severe': 2}\n",
    "to_whom_map = {'None': 0, 'Individual': 1, 'Organization': 2, 'Community': 3, 'Society': 4}\n",
    "id2hate = {v: k for k, v in hate_type_map.items()}\n",
    "id2sev = {v: k for k, v in severity_map.items()}\n",
    "id2to = {v: k for k, v in to_whom_map.items()}\n",
    "\n",
    "# Load training and validation data\n",
    "train_df = pd.read_csv(train_file, sep='\\t')\n",
    "\n",
    "train_df['hate_type'] = train_df['hate_type'].fillna('None')\n",
    "train_df['to_whom'] = train_df['to_whom'].fillna('None')\n",
    "train_df['hate_type'] = train_df['hate_type'].map(hate_type_map).astype(int)\n",
    "train_df['hate_severity'] = train_df['hate_severity'].map(severity_map).astype(int)\n",
    "train_df['to_whom'] = train_df['to_whom'].map(to_whom_map).astype(int)\n",
    "\n",
    "validation_df = pd.read_csv(validation_file, sep='\\t')\n",
    "validation_df['hate_type'] = validation_df['hate_type'].replace('nan', 'None').fillna('None')\n",
    "validation_df['to_whom'] = validation_df['to_whom'].replace('nan', 'None').fillna('None')\n",
    "validation_df['hate_type'] = validation_df['hate_type'].map(hate_type_map).astype(int)\n",
    "validation_df['hate_severity'] = validation_df['hate_severity'].map(severity_map).astype(int)\n",
    "validation_df['to_whom'] = validation_df['to_whom'].map(to_whom_map).astype(int)\n",
    "\n",
    "# # Combine training and validation data for cross-validation\n",
    "combined_df = pd.concat([train_df, validation_df], ignore_index=True)\n",
    "combined_dataset = Dataset.from_pandas(combined_df)\n",
    "\n",
    "# # Load test data separately\n",
    "test_df = pd.read_csv(test_file, sep='\\t')\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Create initial dataset dict for preprocessing\n",
    "raw_datasets = DatasetDict({\n",
    "    \"combined\": combined_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "for key in raw_datasets.keys():\n",
    "    logger.info(f\"loading a local file for {key}\")\n",
    "    \n",
    "print(f\"Combined dataset size: {len(combined_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_df)}\")\n",
    "len(test_df['id'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "class MultiTaskModel(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(model_name)\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_size = self.config.hidden_size\n",
    "        self.hate_type_head = torch.nn.Linear(hidden_size, len(hate_type_map))\n",
    "        self.severity_head = torch.nn.Linear(hidden_size, len(severity_map))\n",
    "        self.to_whom_head = torch.nn.Linear(hidden_size, len(to_whom_map))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        hate_type_logits = self.hate_type_head(pooled_output)\n",
    "        severity_logits = self.severity_head(pooled_output)\n",
    "        to_whom_logits = self.to_whom_head(pooled_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            hate_type_labels = labels[:, 0]\n",
    "            severity_labels = labels[:, 1]\n",
    "            to_whom_labels = labels[:, 2]\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(hate_type_logits, hate_type_labels.long()) + \\\n",
    "                   loss_fct(severity_logits, severity_labels.long()) + \\\n",
    "                   loss_fct(to_whom_logits, to_whom_labels.long())\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=(hate_type_logits, severity_logits, to_whom_logits),\n",
    "        )\n",
    "\n",
    "non_label_column_names = [name for name in raw_datasets[\"combined\"].column_names if name != \"labels\"]\n",
    "sentence1_key= 'text'\n",
    "\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "if max_seq_length > tokenizer.model_max_length:\n",
    "    logger.warning(\n",
    "        f\"The max_seq_length passed ({max_seq_length}) is larger than the maximum length for the\"\n",
    "        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
    "    )\n",
    "max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],))\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    if \"hate_type\" in examples:\n",
    "        result[\"labels\"] = [[l1, l2, l3] for l1, l2, l3 in zip(examples[\"hate_type\"], examples[\"hate_severity\"], examples[\"to_whom\"])]\n",
    "    return result\n",
    "\n",
    "# Preprocess the datasets\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "# Prepare combined dataset for cross-validation\n",
    "combined_dataset = raw_datasets[\"combined\"]\n",
    "predict_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "# Extract features and labels for StratifiedKFold\n",
    "# For stratification, use hate_type_label as primary, since it has more classes\n",
    "X = np.arange(len(combined_dataset))  # Dummy, since we select indices\n",
    "y = np.array(combined_dataset[\"hate_type\"])  # Stratify on hate_type\n",
    "\n",
    "print(f\"Total samples for cross-validation: {len(y)}\")\n",
    "print(f\"Label distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = []\n",
    "fold_probs = []\n",
    "# Cross-validation loop\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    hate_preds = np.argmax(p.predictions[0], axis=1)\n",
    "    sev_preds = np.argmax(p.predictions[1], axis=1)\n",
    "    to_preds = np.argmax(p.predictions[2], axis=1)\n",
    "    hate_labels = p.label_ids[:,0]\n",
    "    sev_labels = p.label_ids[:,1]\n",
    "    to_labels = p.label_ids[:,2]\n",
    "    hate_acc = accuracy.compute(predictions=hate_preds, references=hate_labels)['accuracy']\n",
    "    sev_acc = accuracy.compute(predictions=sev_preds, references=sev_labels)['accuracy']\n",
    "    to_acc = accuracy.compute(predictions=to_preds, references=to_labels)['accuracy']\n",
    "    return {'hate_accuracy': hate_acc, 'severity_accuracy': sev_acc, 'to_whom_accuracy': to_acc}\n",
    "\n",
    "class FreeLB():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "    \n",
    "    def attack(self, input_ids, attention_mask, labels, epsilon=0.3, alpha=0.01, K=3, emb_name='base_model.embeddings.word_embeddings'):\n",
    "        \"\"\"\n",
    "        FreeLB adversarial training implementation\n",
    "        Args:\n",
    "            input_ids: input token ids\n",
    "            attention_mask: attention mask\n",
    "            labels: target labels  \n",
    "            epsilon: maximum perturbation bound\n",
    "            alpha: step size for gradient ascent\n",
    "            K: number of PGD steps\n",
    "            emb_name: name of embedding layer\n",
    "        Returns:\n",
    "            accumulated gradients\n",
    "        \"\"\"\n",
    "        # Get word embeddings\n",
    "        embeddings = None\n",
    "        for name, module in self.model.named_modules():\n",
    "            if 'word_embeddings' in name:\n",
    "                embeddings = module\n",
    "                break\n",
    "        \n",
    "        if embeddings is None:\n",
    "            raise ValueError(\"Could not find word embeddings layer\")\n",
    "            \n",
    "        # Get initial embeddings\n",
    "        embeds_init = embeddings(input_ids)\n",
    "        \n",
    "        # Random initialization of perturbation\n",
    "        if embeds_init.dtype == torch.float16:\n",
    "            delta = torch.zeros_like(embeds_init).uniform_(-epsilon, epsilon).half()\n",
    "        else:\n",
    "            delta = torch.zeros_like(embeds_init).uniform_(-epsilon, epsilon)\n",
    "        delta.requires_grad_()\n",
    "        \n",
    "        # Accumulate gradients\n",
    "        total_grad = 0\n",
    "        \n",
    "        for step in range(K):\n",
    "            # Add perturbation to embeddings\n",
    "            inputs_embeds = embeds_init + delta\n",
    "            \n",
    "            # Forward pass with perturbed embeddings\n",
    "            outputs = self.model(\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Scale loss by 1/K for gradient accumulation\n",
    "            loss = loss / K\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            # Update perturbation via gradient ascent\n",
    "            if step < K - 1:  # Don't update delta on last step\n",
    "                grad = delta.grad.data\n",
    "                norm = torch.norm(grad, p='fro')\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    delta.data = delta.data + alpha * grad / norm\n",
    "                    # Project back to epsilon ball\n",
    "                    delta_norm = torch.norm(delta.data, p='fro')\n",
    "                    if delta_norm > epsilon:\n",
    "                        delta.data = epsilon * delta.data / delta_norm\n",
    "                delta.grad.zero_()\n",
    "        \n",
    "        return embeds_init, delta\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, use_freelb=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_freelb = use_freelb\n",
    "        \n",
    "    def training_step(self, model: torch.nn.Module, inputs: dict, num_items_in_batch: Optional[int] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Memory-optimized FreeLB implementation\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        \n",
    "        # Check if FreeLB is enabled\n",
    "        if not self.use_freelb:\n",
    "            with self.compute_loss_context_manager():\n",
    "                loss = self.compute_loss(model, inputs)\n",
    "            if self.args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.args.gradient_accumulation_steps\n",
    "            if self.args.n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "            self.accelerator.backward(loss)\n",
    "            return loss.detach()\n",
    "            \n",
    "        # FreeLB with aggressive memory optimization\n",
    "        K = 2  # Use only 2 steps to reduce memory\n",
    "        epsilon = 0.2  # Smaller perturbation\n",
    "        alpha = 0.02  # Adjusted step size\n",
    "        \n",
    "        # Try to get word embeddings layer\n",
    "        word_embeddings = None\n",
    "        if hasattr(model, 'base_model'):\n",
    "            if hasattr(model.base_model, 'embeddings'):\n",
    "                if hasattr(model.base_model.embeddings, 'word_embeddings'):\n",
    "                    word_embeddings = model.base_model.embeddings.word_embeddings\n",
    "        \n",
    "        if word_embeddings is None:\n",
    "            # Fallback to standard training if we can't find embeddings\n",
    "            with self.compute_loss_context_manager():\n",
    "                loss = self.compute_loss(model, inputs)\n",
    "            if self.args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.args.gradient_accumulation_steps\n",
    "            if self.args.n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "            self.accelerator.backward(loss)\n",
    "            return loss.detach()\n",
    "        \n",
    "        # Proper FreeLB implementation following the paper\n",
    "        try:\n",
    "            input_ids = inputs.get('input_ids')\n",
    "            batch_size = input_ids.size(0)\n",
    "            \n",
    "            # Get clean embeddings\n",
    "            with torch.no_grad():\n",
    "                embeds_init = word_embeddings(input_ids)\n",
    "            \n",
    "            # Initialize perturbation uniformly in [-ε, ε] as per FreeLB paper\n",
    "            delta = torch.zeros_like(embeds_init).uniform_(-epsilon, epsilon)\n",
    "            \n",
    "            # Normalize to epsilon ball (Frobenius norm)\n",
    "            delta_flat = delta.view(batch_size, -1)\n",
    "            delta_norm = torch.norm(delta_flat, p='fro', dim=1, keepdim=True)\n",
    "            delta = (delta_flat * epsilon / (delta_norm + 1e-8)).view_as(embeds_init)\n",
    "            delta = delta.detach()\n",
    "            delta.requires_grad = True\n",
    "            \n",
    "            # Clear gradients before FreeLB loop\n",
    "            model.zero_grad()\n",
    "            \n",
    "            for step in range(K):\n",
    "                # Create perturbed embeddings\n",
    "                perturbed_embeds = embeds_init + delta\n",
    "                \n",
    "                # Hook to replace embeddings output\n",
    "                def make_hook(perturbed):\n",
    "                    def hook_fn(module, input, output):\n",
    "                        # Only replace for our batch\n",
    "                        return perturbed\n",
    "                    return hook_fn\n",
    "                \n",
    "                hook = word_embeddings.register_forward_hook(make_hook(perturbed_embeds))\n",
    "                \n",
    "                try:\n",
    "                    # Forward pass\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=inputs.get('attention_mask'),\n",
    "                        labels=inputs.get('labels')\n",
    "                    )\n",
    "                    loss = outputs.loss\n",
    "                    \n",
    "                    # Scale loss by 1/K for averaging\n",
    "                    scaled_loss = loss / K\n",
    "                    \n",
    "                    # Account for gradient accumulation\n",
    "                    if self.args.gradient_accumulation_steps > 1:\n",
    "                        scaled_loss = scaled_loss / self.args.gradient_accumulation_steps\n",
    "                    \n",
    "                    # Compute gradients with proper handling for mixed precision\n",
    "                    # Use accelerator for proper gradient scaling with FP16\n",
    "                    if hasattr(self, 'accelerator'):\n",
    "                        self.accelerator.backward(scaled_loss, retain_graph=(step < K-1))\n",
    "                    else:\n",
    "                        scaled_loss.backward(retain_graph=(step < K-1))\n",
    "                    \n",
    "                    # Update adversarial perturbation (except on last step)\n",
    "                    if step < K - 1 and delta.grad is not None:\n",
    "                        # Gradient ascent on delta to maximize loss\n",
    "                        grad = delta.grad.data\n",
    "                        grad_flat = grad.view(batch_size, -1)\n",
    "                        grad_norm = torch.norm(grad_flat, p='fro', dim=1, keepdim=True)\n",
    "                        grad_normalized = (grad_flat / (grad_norm + 1e-8)).view_as(grad)\n",
    "                        \n",
    "                        # Update delta\n",
    "                        delta = delta.detach() + alpha * grad_normalized\n",
    "                        \n",
    "                        # Project back to epsilon ball\n",
    "                        delta_flat = delta.view(batch_size, -1)\n",
    "                        delta_norm = torch.norm(delta_flat, p='fro', dim=1, keepdim=True)\n",
    "                        delta = (delta_flat * epsilon / torch.clamp(delta_norm, min=epsilon)).view_as(embeds_init)\n",
    "                        delta = delta.detach()\n",
    "                        delta.requires_grad = True\n",
    "                        \n",
    "                        # Don't clear model gradients here - we're accumulating across K steps\n",
    "                        \n",
    "                finally:\n",
    "                    hook.remove()\n",
    "            \n",
    "            # Return average loss for logging (loss is already from last step)\n",
    "            return loss.detach()\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to standard training\n",
    "            print(f\"FreeLB error: {e}, using standard training\")\n",
    "            with self.compute_loss_context_manager():\n",
    "                loss = self.compute_loss(model, inputs)\n",
    "            if self.args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.args.gradient_accumulation_steps\n",
    "            if self.args.n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "            self.accelerator.backward(loss)\n",
    "            return loss.detach()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{n_splits}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create train and validation datasets for this fold\n",
    "    train_dataset = combined_dataset.select(train_idx.tolist())\n",
    "    val_dataset = combined_dataset.select(val_idx.tolist())\n",
    "    \n",
    "    # Remove ID columns\n",
    "    train_dataset = train_dataset.remove_columns(\"id\") if \"id\" in train_dataset.column_names else train_dataset\n",
    "    val_dataset = val_dataset.remove_columns(\"id\") if \"id\" in val_dataset.column_names else val_dataset\n",
    "    \n",
    "    print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")\n",
    "    \n",
    "    # Initialize model for this fold (fresh model each time)\n",
    "    model = MultiTaskModel(model_name)\n",
    "    \n",
    "    # Update training arguments for this fold\n",
    "    fold_training_args = TrainingArguments(\n",
    "        learning_rate=2e-5,\n",
    "        num_train_epochs=2,  # Reduced to save memory\n",
    "        per_device_train_batch_size=4,  # Very small batch size for FreeLB\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=4,  # Maintain effective batch size of 16\n",
    "        output_dir=f\"./freelb_fold_{fold+1}/\",\n",
    "        overwrite_output_dir=True,\n",
    "        remove_unused_columns=True,  # Changed to True to fix the tensor conversion error\n",
    "        local_rank=1,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=None,\n",
    "        warmup_ratio=0.1,  # Add warmup as recommended\n",
    "        weight_decay=0.01,  # Add weight decay for regularization\n",
    "        fp16=False,  # Disable FP16 for FreeLB compatibility\n",
    "        seed=42 + fold  # Different seed for each fold\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer for this fold - Enable FreeLB only for first fold to test\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=fold_training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        use_freelb=True  # Set to False if memory issues persist\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"Evaluating fold {fold + 1}...\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    \n",
    "    # Store results\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'train_loss': train_result.metrics['train_loss'],\n",
    "        'eval_loss': eval_result['eval_loss'],\n",
    "        'eval_hate_accuracy': eval_result['eval_hate_accuracy'],\n",
    "        'eval_severity_accuracy': eval_result['eval_severity_accuracy'],\n",
    "        'eval_to_whom_accuracy': eval_result['eval_to_whom_accuracy']\n",
    "    })\n",
    "    \n",
    "    # Generate predictions on test set for this fold\n",
    "    print(f\"Predicting with fold {fold + 1} model...\")\n",
    "    test_predictions = trainer.predict(predict_dataset.remove_columns(\"id\") if \"id\" in predict_dataset.column_names else predict_dataset)\n",
    "    probs = [torch.softmax(torch.tensor(logits), dim=-1).numpy() for logits in test_predictions.predictions]\n",
    "    fold_probs.append(probs)\n",
    "    \n",
    "    # Clean up to save memory\n",
    "    del model, trainer\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Hate Accuracy: {eval_result['eval_hate_accuracy']:.4f}, Severity Accuracy: {eval_result['eval_severity_accuracy']:.4f}, To Whom Accuracy: {eval_result['eval_to_whom_accuracy']:.4f}\")\n",
    "    \n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CROSS-VALIDATION COMPLETED\")\n",
    "print(f\"{'='*50}\")\n",
    "# Analyze cross-validation results\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate average performance metrics\n",
    "avg_train_loss = results_df['train_loss'].mean()\n",
    "avg_eval_loss = results_df['eval_loss'].mean()\n",
    "avg_hate_acc = results_df['eval_hate_accuracy'].mean()\n",
    "avg_sev_acc = results_df['eval_severity_accuracy'].mean()\n",
    "avg_to_acc = results_df['eval_to_whom_accuracy'].mean()\n",
    "std_hate_acc = results_df['eval_hate_accuracy'].std()\n",
    "std_sev_acc = results_df['eval_severity_accuracy'].std()\n",
    "std_to_acc = results_df['eval_to_whom_accuracy'].std()\n",
    "\n",
    "print(f\"\\nAverage Results Across {n_splits} Folds:\")\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_eval_loss:.4f}\")\n",
    "print(f\"Average Hate Type Accuracy: {avg_hate_acc:.4f} ± {std_hate_acc:.4f}\")\n",
    "print(f\"Average Severity Accuracy: {avg_sev_acc:.4f} ± {std_sev_acc:.4f}\")\n",
    "print(f\"Average To Whom Accuracy: {avg_to_acc:.4f} ± {std_to_acc:.4f}\")\n",
    "\n",
    "# Ensemble predictions\n",
    "hate_probs_folds = np.array([probs[0] for probs in fold_probs])\n",
    "sev_probs_folds = np.array([probs[1] for probs in fold_probs])\n",
    "to_probs_folds = np.array([probs[2] for probs in fold_probs])\n",
    "ensemble_probs = (np.mean(hate_probs_folds, axis=0),\n",
    "                  np.mean(sev_probs_folds, axis=0),\n",
    "                  np.mean(to_probs_folds, axis=0))\n",
    "# np.save('ensemble_probs_aug20.npy', np.array(ensemble_probs, dtype=object))\n",
    "# Final ensemble prediction\n",
    "hate_probs, sev_probs, to_probs = ensemble_probs\n",
    "final_hate_preds = np.argmax(hate_probs, axis=1)\n",
    "final_sev_preds = np.argmax(sev_probs, axis=1)\n",
    "final_to_preds = np.argmax(to_probs, axis=1)\n",
    "\n",
    "# Generate predictions\n",
    "\n",
    "\n",
    "# # Also save the ensemble predictions with different format for comparison\n",
    "# submission_df = pd.DataFrame({'id': test_df['id'], 'hate_type': [id2hate[p] for p in final_hate_preds], 'hate_severity': [id2sev[p] for p in final_sev_preds], 'to_whom': [id2to[p] for p in final_to_preds]})\n",
    "# submission_df.to_csv('ensemble_submission.tsv', sep='\\t', index=False)\n",
    "\n",
    "# print(\"Ensemble predictions also saved to 'ensemble_submission.tsv'\")\n",
    "import os\n",
    "os.makedirs(training_args.output_dir, exist_ok=True)\n",
    "logger.info(\"*** Predict ***\")\n",
    "ids = test_df['id']\n",
    "output_predict_file = os.path.join(training_args.output_dir, f\"subtask_1C.tsv\")\n",
    "\n",
    "# Write predictions in the required format\n",
    "with open(output_predict_file, \"w\") as writer:\n",
    "    logger.info(f\"***** Predict results *****\")\n",
    "    writer.write(\"id\\thate_type\\thate_severity\\tto_whom\\tmodel\\n\")\n",
    "    for index in range(len(final_hate_preds)):\n",
    "        h = id2hate[final_hate_preds[index]]\n",
    "        s = id2sev[final_sev_preds[index]]\n",
    "        t = id2to[final_to_preds[index]]\n",
    "        writer.write(f\"{ids[index]}\\t{h}\\t{s}\\t{t}\\t{model_name}\\n\")\n",
    "\n",
    "print(f\"\\nPredictions saved to '{output_predict_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21920.279993,
   "end_time": "2025-08-28T07:29:52.316057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-28T01:24:32.036064",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "008f7d871ae0473783cf263b3cc2b659": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03598c2742b34a7d9aaec9195fc58a13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_77fbe097013147e394ee0f8433ac56df",
       "max": 586.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_270ee4137424469682d094ac66930bc3",
       "tabbable": null,
       "tooltip": null,
       "value": 586.0
      }
     },
     "0738c22af4f74739b466cbb800e81190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78dedb9511884b9891585b5fae3d897a",
       "placeholder": "​",
       "style": "IPY_MODEL_64c74317904442e0911e6b00276739f1",
       "tabbable": null,
       "tooltip": null,
       "value": " 443M/443M [00:02&lt;00:00, 205MB/s]"
      }
     },
     "0a08588d7c4e4402823b3421f4b774fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a69432f740f341408f05f89fcb6c654d",
       "placeholder": "​",
       "style": "IPY_MODEL_bbc4eec58c324a49b275106c80ac3b58",
       "tabbable": null,
       "tooltip": null,
       "value": "Running tokenizer on dataset: 100%"
      }
     },
     "0b2677f466284d3eaccba8bc0ace2745": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_008f7d871ae0473783cf263b3cc2b659",
       "placeholder": "​",
       "style": "IPY_MODEL_47903529e9844d1a99a3be5c696b4e8e",
       "tabbable": null,
       "tooltip": null,
       "value": " 2512/2512 [00:00&lt;00:00, 3213.97 examples/s]"
      }
     },
     "0b611fe788c1495e9b59b3dea888ae54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "150b32c432a04a1a80234c85273e8b7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "16b29c45a3a04488913d5c9b9ce830d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17edc3b70eb84b49a58bba8eb1c605f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_faf68e30e2d443abaf43c61d28115974",
       "max": 442560329.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1be87139b3154f62b64d7a97e66a2df0",
       "tabbable": null,
       "tooltip": null,
       "value": 442560329.0
      }
     },
     "1a93da417b554101a5d47196d2794fe1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bbbe10581dc4fdbb8528a713ceaaf69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1be87139b3154f62b64d7a97e66a2df0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d487e2d56a342c3bc5d10aba7201d93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1f428518537b4ce89d8c93bb85853bf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "23d444f87d724538a88f975113110b63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25d238a32f764eb58095a71faa667671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "270ee4137424469682d094ac66930bc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2900d3368c544c30b016fd0973c2cc51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "291581a6a8cd41559a089159bf9d7bbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3031110d7693413ebf6a8a1016f7e587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b611fe788c1495e9b59b3dea888ae54",
       "placeholder": "​",
       "style": "IPY_MODEL_780aa650afad4d42af6f1632e009e059",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: "
      }
     },
     "32da63c6688d4059904cab724c6f7d75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33a403805fe643c692b36e7341067403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84d043bd096c4b14aef955473c0cac22",
       "placeholder": "​",
       "style": "IPY_MODEL_1bbbe10581dc4fdbb8528a713ceaaf69",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "341b7c2c3e004ce58f85b425bc2e6576": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9725a2b9f8db4b7e98178a3ec234c9f6",
        "IPY_MODEL_03598c2742b34a7d9aaec9195fc58a13",
        "IPY_MODEL_98c6283a9f394d73b1095be933605225"
       ],
       "layout": "IPY_MODEL_498aa62716464294ac6d1d47f44b1c14",
       "tabbable": null,
       "tooltip": null
      }
     },
     "385af9d36fe242889e155c388dca7d9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3871256f5bcc4e1dbc9e0fc7191eeaed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d5d840158054a8fadc750efe69f71f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c103a9815584ef186408efcdd24dd31",
       "max": 119.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d5b3a51624944a5c8b58060df9d61e3a",
       "tabbable": null,
       "tooltip": null,
       "value": 119.0
      }
     },
     "3e852e142fea43a6b7b31519c14e3aac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42fc8c68375241f9973afbd030e6b6f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d6e00bec21b64baca829649c14d98faf",
       "max": 38034.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f6cdb727380b40779e8040da2934950a",
       "tabbable": null,
       "tooltip": null,
       "value": 38034.0
      }
     },
     "436bfc6dbcaf43a6868b48b6037958de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "45feb827873241128e0d04ee0ea9aff8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4746a1183ca491786ba1863e4623af1",
       "placeholder": "​",
       "style": "IPY_MODEL_9c74dbafdd3b4ee7b22d6ee66a9c97cd",
       "tabbable": null,
       "tooltip": null,
       "value": " 119/119 [00:00&lt;00:00, 11.6kB/s]"
      }
     },
     "468bffdc1d7041f08061c45a5f311468": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d72f06884f80480b9815bf1611e35712",
       "placeholder": "​",
       "style": "IPY_MODEL_436bfc6dbcaf43a6868b48b6037958de",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "47903529e9844d1a99a3be5c696b4e8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "47a26875e18644d69ec607cf01fc714a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b59b1c4ca7214898a0eb6061248009d9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a0d6f4bb9b8e4cd68890eabb5fdb280d",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "498aa62716464294ac6d1d47f44b1c14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bffd7662d2a4cd5a65ebc3e23614b6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_385af9d36fe242889e155c388dca7d9e",
       "placeholder": "​",
       "style": "IPY_MODEL_e581bb28a1074289bfd9d4d8df682ac2",
       "tabbable": null,
       "tooltip": null,
       "value": " 443M/443M [00:02&lt;00:00, 243MB/s]"
      }
     },
     "5196a5ac926f4465b03a0f6cb12fcd76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cc02eeae36164e76926ce4eeebe0251c",
       "placeholder": "​",
       "style": "IPY_MODEL_bf490bc0abe741869f2c4e82788d922d",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 14.3kB/s]"
      }
     },
     "64c74317904442e0911e6b00276739f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "758705a73de64c039071bc7e0384debe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dda4bf6a278f455585b8541519ceb888",
        "IPY_MODEL_42fc8c68375241f9973afbd030e6b6f4",
        "IPY_MODEL_b0d93c8cef0943b987a852bf119dde8d"
       ],
       "layout": "IPY_MODEL_caabe2812f9e4da7aa96187f25a6230b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "762d888443df4dbfa3dc7f667d181b37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fcda4acef7334f6e99132362dc91c5cd",
        "IPY_MODEL_47a26875e18644d69ec607cf01fc714a",
        "IPY_MODEL_cbd8d8d435e642beb1e5794a4f397fa7"
       ],
       "layout": "IPY_MODEL_76f791e60893485fbe1c3b2a2039be10",
       "tabbable": null,
       "tooltip": null
      }
     },
     "76f791e60893485fbe1c3b2a2039be10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77fbe097013147e394ee0f8433ac56df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "780aa650afad4d42af6f1632e009e059": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "782900fb79144996b9fbaf7fd6cc6e69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78bb5e8b511f4797aa41aef80dd736e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78dedb9511884b9891585b5fae3d897a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a320f3424a3481aa34cc90693e718d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c103a9815584ef186408efcdd24dd31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84d043bd096c4b14aef955473c0cac22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85dea3bc58704b71afdf699524852736": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "885de8f77914462e8ba0e8decf8cd29c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a6c186b0dbe490d9e79ff978a500e1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c98facf759e486f8231e0b70d0abda4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8d3da277cfcb4e88ab90830d3455ccf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "966eafca8c464b94bfbb1ace7e00ffd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9725a2b9f8db4b7e98178a3ec234c9f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cf32ab7ded164faba8f8a65afbe1455a",
       "placeholder": "​",
       "style": "IPY_MODEL_16b29c45a3a04488913d5c9b9ce830d7",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "988f9a3a168843298011dfc4371e0a16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98c6283a9f394d73b1095be933605225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_782900fb79144996b9fbaf7fd6cc6e69",
       "placeholder": "​",
       "style": "IPY_MODEL_966eafca8c464b94bfbb1ace7e00ffd5",
       "tabbable": null,
       "tooltip": null,
       "value": " 586/586 [00:00&lt;00:00, 71.7kB/s]"
      }
     },
     "9b504bb2195149538fd86ddbc08b047c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c74dbafdd3b4ee7b22d6ee66a9c97cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d3210c6d4714bf9b0eab5eb0c10bd4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a06c4db7b2474b6daec0650d1f45ef47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23d444f87d724538a88f975113110b63",
       "placeholder": "​",
       "style": "IPY_MODEL_baaa13523a564ac8b89528d2a890af98",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "a0d6f4bb9b8e4cd68890eabb5fdb280d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a16204103c5242c5a05b7cb0ea5f37e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_33a403805fe643c692b36e7341067403",
        "IPY_MODEL_3d5d840158054a8fadc750efe69f71f1",
        "IPY_MODEL_45feb827873241128e0d04ee0ea9aff8"
       ],
       "layout": "IPY_MODEL_b4023925711c4242ab4c4781d8a81dc3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a198cd742ac045eda8a16befe67fc975": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d487e2d56a342c3bc5d10aba7201d93",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b6402bab6dfb41668d3bff2a3020ecf3",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "a2b120d44bb44c50acbd8b936b855f47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3031110d7693413ebf6a8a1016f7e587",
        "IPY_MODEL_a198cd742ac045eda8a16befe67fc975",
        "IPY_MODEL_ee69e8f817b64ed3bf041f45be595574"
       ],
       "layout": "IPY_MODEL_32da63c6688d4059904cab724c6f7d75",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a69432f740f341408f05f89fcb6c654d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8d53e042f0a476a9e67a002c4c28d71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afbf9cec6a07475c9ce44867b8587672": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a06c4db7b2474b6daec0650d1f45ef47",
        "IPY_MODEL_f923447d994f41d1b7ea7042a492016d",
        "IPY_MODEL_0738c22af4f74739b466cbb800e81190"
       ],
       "layout": "IPY_MODEL_3e852e142fea43a6b7b31519c14e3aac",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b0d93c8cef0943b987a852bf119dde8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3871256f5bcc4e1dbc9e0fc7191eeaed",
       "placeholder": "​",
       "style": "IPY_MODEL_988f9a3a168843298011dfc4371e0a16",
       "tabbable": null,
       "tooltip": null,
       "value": " 38034/38034 [00:12&lt;00:00, 2605.03 examples/s]"
      }
     },
     "b4023925711c4242ab4c4781d8a81dc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4746a1183ca491786ba1863e4623af1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b59b1c4ca7214898a0eb6061248009d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b6402bab6dfb41668d3bff2a3020ecf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b67ac9527f1c4a6c9b0b8f08b8c348a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bc2375ee562b4e399bd2e33d7c825be5",
        "IPY_MODEL_17edc3b70eb84b49a58bba8eb1c605f2",
        "IPY_MODEL_4bffd7662d2a4cd5a65ebc3e23614b6c"
       ],
       "layout": "IPY_MODEL_a8d53e042f0a476a9e67a002c4c28d71",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b7eb36927bb44924be63fbf115ef49f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "baaa13523a564ac8b89528d2a890af98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bbc4eec58c324a49b275106c80ac3b58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc2375ee562b4e399bd2e33d7c825be5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b504bb2195149538fd86ddbc08b047c",
       "placeholder": "​",
       "style": "IPY_MODEL_fd190edbe6c64441a7246619cebc7671",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "bf490bc0abe741869f2c4e82788d922d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c950739aa18e45229d4bdb3ba91c7c4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_468bffdc1d7041f08061c45a5f311468",
        "IPY_MODEL_eaa803f1d34543869e31877d54d804c3",
        "IPY_MODEL_5196a5ac926f4465b03a0f6cb12fcd76"
       ],
       "layout": "IPY_MODEL_2900d3368c544c30b016fd0973c2cc51",
       "tabbable": null,
       "tooltip": null
      }
     },
     "caabe2812f9e4da7aa96187f25a6230b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cac0103cf47f4b65b0eebca62df04e5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_885de8f77914462e8ba0e8decf8cd29c",
       "max": 2512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_291581a6a8cd41559a089159bf9d7bbf",
       "tabbable": null,
       "tooltip": null,
       "value": 2512.0
      }
     },
     "cbd8d8d435e642beb1e5794a4f397fa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_85dea3bc58704b71afdf699524852736",
       "placeholder": "​",
       "style": "IPY_MODEL_150b32c432a04a1a80234c85273e8b7c",
       "tabbable": null,
       "tooltip": null,
       "value": " 4.20k/? [00:00&lt;00:00, 453kB/s]"
      }
     },
     "cc02eeae36164e76926ce4eeebe0251c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf32ab7ded164faba8f8a65afbe1455a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5b3a51624944a5c8b58060df9d61e3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d6e00bec21b64baca829649c14d98faf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d72f06884f80480b9815bf1611e35712": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dda4bf6a278f455585b8541519ceb888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d3210c6d4714bf9b0eab5eb0c10bd4d",
       "placeholder": "​",
       "style": "IPY_MODEL_fade43fe671b416c8734ce0c579e2af0",
       "tabbable": null,
       "tooltip": null,
       "value": "Running tokenizer on dataset: 100%"
      }
     },
     "e581bb28a1074289bfd9d4d8df682ac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eaa803f1d34543869e31877d54d804c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a6c186b0dbe490d9e79ff978a500e1f",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8c98facf759e486f8231e0b70d0abda4",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "ee69e8f817b64ed3bf041f45be595574": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25d238a32f764eb58095a71faa667671",
       "placeholder": "​",
       "style": "IPY_MODEL_1a93da417b554101a5d47196d2794fe1",
       "tabbable": null,
       "tooltip": null,
       "value": " 528k/? [00:00&lt;00:00, 14.2MB/s]"
      }
     },
     "f254bc70923242168023cb63cd007d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a08588d7c4e4402823b3421f4b774fd",
        "IPY_MODEL_cac0103cf47f4b65b0eebca62df04e5a",
        "IPY_MODEL_0b2677f466284d3eaccba8bc0ace2745"
       ],
       "layout": "IPY_MODEL_78bb5e8b511f4797aa41aef80dd736e3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f6cdb727380b40779e8040da2934950a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f923447d994f41d1b7ea7042a492016d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a320f3424a3481aa34cc90693e718d9",
       "max": 442500860.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8d3da277cfcb4e88ab90830d3455ccf6",
       "tabbable": null,
       "tooltip": null,
       "value": 442500860.0
      }
     },
     "fade43fe671b416c8734ce0c579e2af0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "faf68e30e2d443abaf43c61d28115974": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcda4acef7334f6e99132362dc91c5cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7eb36927bb44924be63fbf115ef49f6",
       "placeholder": "​",
       "style": "IPY_MODEL_1f428518537b4ce89d8c93bb85853bf7",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "fd190edbe6c64441a7246619cebc7671": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
